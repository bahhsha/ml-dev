{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-1 Accuracy(정확도)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22.1\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "class MyDummyClassifier(BaseEstimator):\n",
    "    # fit( ) 메소드는 아무것도 학습하지 않음. \n",
    "    def fit(self, X , y=None):\n",
    "        pass\n",
    "    \n",
    "    # predict( ) 메소드는 단순히 Sex feature가 1 이면 0 , 그렇지 않으면 1 로 예측함. \n",
    "    def predict(self, X):\n",
    "        pred = np.zeros( ( X.shape[0], 1 ))\n",
    "        for i in range (X.shape[0]) :\n",
    "            if X['Sex'].iloc[i] == 1:\n",
    "                pred[i] = 0\n",
    "            else :\n",
    "                pred[i] = 1\n",
    "        \n",
    "        return pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Null 처리 함수\n",
    "def fillna(df):\n",
    "    df['Age'].fillna(df['Age'].mean(),inplace=True)\n",
    "    df['Cabin'].fillna('N',inplace=True)\n",
    "    df['Embarked'].fillna('N',inplace=True)\n",
    "    df['Fare'].fillna(0,inplace=True)\n",
    "    return df\n",
    "\n",
    "# 머신러닝 알고리즘에 불필요한 속성 제거\n",
    "def drop_features(df):\n",
    "    df.drop(['PassengerId','Name','Ticket'],axis=1,inplace=True)\n",
    "    return df\n",
    "\n",
    "# 레이블 인코딩 수행. \n",
    "def format_features(df):\n",
    "    df['Cabin'] = df['Cabin'].str[:1]\n",
    "    features = ['Cabin','Sex','Embarked']\n",
    "    for feature in features:\n",
    "        le = LabelEncoder()\n",
    "        le = le.fit(df[feature])\n",
    "        df[feature] = le.transform(df[feature])\n",
    "    return df\n",
    "\n",
    "# 앞에서 설정한 Data Preprocessing 함수 호출\n",
    "def transform_features(df):\n",
    "    df = fillna(df)\n",
    "    df = drop_features(df)\n",
    "    df = format_features(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy Classifier의 정확도는: 0.7877\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 원본 데이터를 재로딩, 데이터 가공, 학습데이터/테스트 데이터 분할. \n",
    "titanic_df = pd.read_csv('./titanic_train.csv')\n",
    "y_titanic_df = titanic_df['Survived']\n",
    "X_titanic_df= titanic_df.drop('Survived', axis=1)\n",
    "X_titanic_df = transform_features(X_titanic_df)\n",
    "X_train, X_test, y_train, y_test=train_test_split(X_titanic_df, y_titanic_df, \\\n",
    "                                                  test_size=0.2, random_state=0)\n",
    "\n",
    "# 위에서 생성한 Dummy Classifier를 이용하여 학습/예측/평가 수행. \n",
    "myclf = MyDummyClassifier()\n",
    "myclf.fit(X_train ,y_train)\n",
    "\n",
    "mypredictions = myclf.predict(X_test)\n",
    "print('Dummy Classifier의 정확도는: {0:.4f}'.format(accuracy_score(y_test , mypredictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  5. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ... 10.  0.  0.]\n",
      " [ 0.  0.  0. ... 16.  9.  0.]\n",
      " ...\n",
      " [ 0.  0.  1. ...  6.  0.  0.]\n",
      " [ 0.  0.  2. ... 12.  0.  0.]\n",
      " [ 0.  0. 10. ... 12.  1.  0.]]\n",
      "### digits.data.shape: (1797, 64)\n",
      "[0 1 2 ... 8 9 8]\n",
      "### digits.target.shape: (1797,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class MyFakeClassifier(BaseEstimator):\n",
    "    def fit(self,X,y):\n",
    "        pass\n",
    "    \n",
    "    # 입력값으로 들어오는 X 데이터 셋의 크기만큼 모두 0값으로 만들어서 반환\n",
    "    def predict(self,X):\n",
    "        return np.zeros( (len(X), 1) , dtype=bool)\n",
    "\n",
    "# 사이킷런의 내장 데이터 셋인 load_digits( )를 이용하여 MNIST 데이터 로딩\n",
    "digits = load_digits()\n",
    "\n",
    "print(digits.data)\n",
    "print(\"### digits.data.shape:\", digits.data.shape)\n",
    "print(digits.target)\n",
    "print(\"### digits.target.shape:\", digits.target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, ..., False, False, False])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.target == 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# digits번호가 7번이면 True이고 이를 astype(int)로 1로 변환, 7번이 아니면 False이고 0으로 변환. \n",
    "y = (digits.target == 7).astype(int)\n",
    "X_train, X_test, y_train, y_test = train_test_split( digits.data, y, random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "레이블 테스트 세트 크기 : (450,)\n",
      "테스트 세트 레이블 0 과 1의 분포도\n",
      "0    405\n",
      "1     45\n",
      "dtype: int64\n",
      "모든 예측을 0으로 하여도 정확도는:0.900\n"
     ]
    }
   ],
   "source": [
    "# 불균형한 레이블 데이터 분포도 확인. \n",
    "print('레이블 테스트 세트 크기 :', y_test.shape)\n",
    "print('테스트 세트 레이블 0 과 1의 분포도')\n",
    "print(pd.Series(y_test).value_counts())\n",
    "\n",
    "# Dummy Classifier로 학습/예측/정확도 평가\n",
    "fakeclf = MyFakeClassifier()\n",
    "fakeclf.fit(X_train , y_train)\n",
    "fakepred = fakeclf.predict(X_test)\n",
    "print('모든 예측을 0으로 하여도 정확도는:{:.3f}'.format(accuracy_score(y_test , fakepred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[405,   0],\n",
       "       [ 45,   0]], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# 앞절의 예측 결과인 fakepred와 실제 결과인 y_test의 Confusion Matrix출력\n",
    "confusion_matrix(y_test , fakepred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 정밀도(Precision) 과 재현율(Recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** MyFakeClassifier의 예측 결과로 정밀도와 재현율 측정**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정밀도: 0.0\n",
      "재현율: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\q\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score , recall_score\n",
    "\n",
    "print(\"정밀도:\", precision_score(y_test, fakepred))\n",
    "print(\"재현율:\", recall_score(y_test, fakepred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 오차행렬, 정확도, 정밀도, 재현율을 한꺼번에 계산하는 함수 생성 **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score , recall_score , confusion_matrix\n",
    "\n",
    "def get_clf_eval(y_test , pred):\n",
    "    confusion = confusion_matrix( y_test, pred)\n",
    "    accuracy = accuracy_score(y_test , pred)\n",
    "    precision = precision_score(y_test , pred)\n",
    "    recall = recall_score(y_test , pred)\n",
    "    print('오차 행렬')\n",
    "    print(confusion)\n",
    "    print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f}'.format(accuracy , precision ,recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차 행렬\n",
      "[[104  14]\n",
      " [ 13  48]]\n",
      "정확도: 0.8492, 정밀도: 0.7742, 재현율: 0.7869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\q\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# 원본 데이터를 재로딩, 데이터 가공, 학습데이터/테스트 데이터 분할. \n",
    "titanic_df = pd.read_csv('./titanic_train.csv')\n",
    "y_titanic_df = titanic_df['Survived']\n",
    "X_titanic_df= titanic_df.drop('Survived', axis=1)\n",
    "X_titanic_df = transform_features(X_titanic_df)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_titanic_df, y_titanic_df, \\\n",
    "                                                    test_size=0.20, random_state=11)\n",
    "\n",
    "lr_clf = LogisticRegression()\n",
    "\n",
    "lr_clf.fit(X_train , y_train)\n",
    "pred = lr_clf.predict(X_test)\n",
    "get_clf_eval(y_test , pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision/Recall Trade-off"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** predict_proba( ) 메소드 확인 **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred_proba()결과 Shape : (179, 2)\n",
      "pred_proba array에서 앞 3개만 샘플로 추출 \n",
      ": [[0.46162417 0.53837583]\n",
      " [0.87858538 0.12141462]\n",
      " [0.87723741 0.12276259]]\n",
      "두개의 class 중에서 더 큰 확률을 클래스 값으로 예측 \n",
      " [[0.46162417 0.53837583 1.        ]\n",
      " [0.87858538 0.12141462 0.        ]\n",
      " [0.87723741 0.12276259 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "pred_proba = lr_clf.predict_proba(X_test)\n",
    "pred  = lr_clf.predict(X_test)\n",
    "print('pred_proba()결과 Shape : {0}'.format(pred_proba.shape))\n",
    "print('pred_proba array에서 앞 3개만 샘플로 추출 \\n:', pred_proba[:3])\n",
    "\n",
    "# 예측 확률 array 와 예측 결과값 array 를 concatenate 하여 예측 확률과 결과값을 한눈에 확인\n",
    "pred_proba_result = np.concatenate([pred_proba , pred.reshape(-1,1)],axis=1)\n",
    "print('두개의 class 중에서 더 큰 확률을 클래스 값으로 예측 \\n',pred_proba_result[:3])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Binarizer 활용 **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import Binarizer\n",
    "\n",
    "X = [[ 1, -1,  2],\n",
    "     [ 2,  0,  0],\n",
    "     [ 0,  1.1, 1.2]]\n",
    "\n",
    "# threshold 기준값보다 같거나 작으면 0을, 크면 1을 반환\n",
    "binarizer = Binarizer(threshold=1.1)                     \n",
    "print(binarizer.fit_transform(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 분류 결정 임계값 0.5 기반에서 Binarizer를 이용하여 예측값 변환 **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차 행렬\n",
      "[[104  14]\n",
      " [ 13  48]]\n",
      "정확도: 0.8492, 정밀도: 0.7742, 재현율: 0.7869\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import Binarizer\n",
    "\n",
    "#Binarizer의 threshold 설정값. 분류 결정 임곗값임.  \n",
    "custom_threshold = 0.5\n",
    "\n",
    "# predict_proba( ) 반환값의 두번째 컬럼 , 즉 Positive 클래스 컬럼 하나만 추출하여 Binarizer를 적용\n",
    "pred_proba_1 = pred_proba[:,1].reshape(-1,1)\n",
    "\n",
    "binarizer = Binarizer(threshold=custom_threshold).fit(pred_proba_1) \n",
    "custom_predict = binarizer.transform(pred_proba_1)\n",
    "\n",
    "get_clf_eval(y_test, custom_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 분류 결정 임계값 0.4 기반에서 Binarizer를 이용하여 예측값 변환 **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차 행렬\n",
      "[[99 19]\n",
      " [10 51]]\n",
      "정확도: 0.8380, 정밀도: 0.7286, 재현율: 0.8361\n"
     ]
    }
   ],
   "source": [
    "# Binarizer의 threshold 설정값을 0.4로 설정. 즉 분류 결정 임곗값을 0.5에서 0.4로 낮춤  \n",
    "custom_threshold = 0.4\n",
    "pred_proba_1 = pred_proba[:,1].reshape(-1,1)\n",
    "binarizer = Binarizer(threshold=custom_threshold).fit(pred_proba_1) \n",
    "custom_predict = binarizer.transform(pred_proba_1)\n",
    "\n",
    "get_clf_eval(y_test , custom_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 여러개의 분류 결정 임곗값을 변경하면서  Binarizer를 이용하여 예측값 변환 **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "임곗값: 0.4\n",
      "오차 행렬\n",
      "[[99 19]\n",
      " [10 51]]\n",
      "정확도: 0.8380, 정밀도: 0.7286, 재현율: 0.8361\n",
      "임곗값: 0.45\n",
      "오차 행렬\n",
      "[[103  15]\n",
      " [ 12  49]]\n",
      "정확도: 0.8492, 정밀도: 0.7656, 재현율: 0.8033\n",
      "임곗값: 0.5\n",
      "오차 행렬\n",
      "[[104  14]\n",
      " [ 13  48]]\n",
      "정확도: 0.8492, 정밀도: 0.7742, 재현율: 0.7869\n",
      "임곗값: 0.55\n",
      "오차 행렬\n",
      "[[109   9]\n",
      " [ 15  46]]\n",
      "정확도: 0.8659, 정밀도: 0.8364, 재현율: 0.7541\n",
      "임곗값: 0.6\n",
      "오차 행렬\n",
      "[[112   6]\n",
      " [ 16  45]]\n",
      "정확도: 0.8771, 정밀도: 0.8824, 재현율: 0.7377\n"
     ]
    }
   ],
   "source": [
    "# 테스트를 수행할 모든 임곗값을 리스트 객체로 저장. \n",
    "thresholds = [0.4, 0.45, 0.50, 0.55, 0.60]\n",
    "\n",
    "def get_eval_by_threshold(y_test , pred_proba_c1, thresholds):\n",
    "    # thresholds list객체내의 값을 차례로 iteration하면서 Evaluation 수행.\n",
    "    for custom_threshold in thresholds:\n",
    "        binarizer = Binarizer(threshold=custom_threshold).fit(pred_proba_c1) \n",
    "        custom_predict = binarizer.transform(pred_proba_c1)\n",
    "        print('임곗값:',custom_threshold)\n",
    "        get_clf_eval(y_test , custom_predict)\n",
    "\n",
    "get_eval_by_threshold(y_test ,pred_proba[:,1].reshape(-1,1), thresholds )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** precision_recall_curve( ) 를 이용하여 임곗값에 따른 정밀도-재현율 값 추출 **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "반환된 분류 결정 임곗값 배열의 Shape: (143,)\n",
      "반환된 precisions 배열의 Shape: (144,)\n",
      "반환된 recalls 배열의 Shape: (144,)\n",
      "thresholds 5 sample: [0.10396312 0.10396534 0.10399023 0.10736008 0.10894927]\n",
      "precisions 5 sample: [0.38853503 0.38461538 0.38709677 0.38961039 0.38562092]\n",
      "recalls 5 sample: [1.         0.98360656 0.98360656 0.98360656 0.96721311]\n",
      "샘플 추출을 위한 임계값 배열의 index 10개: [  0  15  30  45  60  75  90 105 120 135]\n",
      "샘플용 10개의 임곗값:  [0.1  0.12 0.14 0.19 0.28 0.4  0.56 0.67 0.82 0.95]\n",
      "샘플 임계값별 정밀도:  [0.389 0.44  0.466 0.539 0.647 0.729 0.836 0.949 0.958 1.   ]\n",
      "샘플 임계값별 재현율:  [1.    0.967 0.902 0.902 0.902 0.836 0.754 0.607 0.377 0.148]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "# 레이블 값이 1일때의 예측 확률을 추출 \n",
    "pred_proba_class1 = lr_clf.predict_proba(X_test)[:, 1] \n",
    "\n",
    "# 실제값 데이터 셋과 레이블 값이 1일 때의 예측 확률을 precision_recall_curve 인자로 입력 \n",
    "precisions, recalls, thresholds = precision_recall_curve(y_test, pred_proba_class1 )\n",
    "print('반환된 분류 결정 임곗값 배열의 Shape:', thresholds.shape)\n",
    "print('반환된 precisions 배열의 Shape:', precisions.shape)\n",
    "print('반환된 recalls 배열의 Shape:', recalls.shape)\n",
    "\n",
    "print(\"thresholds 5 sample:\", thresholds[:5])\n",
    "print(\"precisions 5 sample:\", precisions[:5])\n",
    "print(\"recalls 5 sample:\", recalls[:5])\n",
    "\n",
    "#반환된 임계값 배열 로우가 147건이므로 샘플로 10건만 추출하되, 임곗값을 15 Step으로 추출. \n",
    "thr_index = np.arange(0, thresholds.shape[0], 15)\n",
    "print('샘플 추출을 위한 임계값 배열의 index 10개:', thr_index)\n",
    "print('샘플용 10개의 임곗값: ', np.round(thresholds[thr_index], 2))\n",
    "\n",
    "# 15 step 단위로 추출된 임계값에 따른 정밀도와 재현율 값 \n",
    "print('샘플 임계값별 정밀도: ', np.round(precisions[thr_index], 3))\n",
    "print('샘플 임계값별 재현율: ', np.round(recalls[thr_index], 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 임곗값의 변경에 따른 정밀도-재현율 변화 곡선을 그림 **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "%matplotlib inline\n",
    "\n",
    "def precision_recall_curve_plot(y_test , pred_proba_c1):\n",
    "    # threshold ndarray와 이 threshold에 따른 정밀도, 재현율 ndarray 추출. \n",
    "    precisions, recalls, thresholds = precision_recall_curve( y_test, pred_proba_c1)\n",
    "    \n",
    "    # X축을 threshold값으로, Y축은 정밀도, 재현율 값으로 각각 Plot 수행. 정밀도는 점선으로 표시\n",
    "    plt.figure(figsize=(8,6))\n",
    "    threshold_boundary = thresholds.shape[0]\n",
    "    plt.plot(thresholds, precisions[0:threshold_boundary], linestyle='--', label='precision')\n",
    "    plt.plot(thresholds, recalls[0:threshold_boundary],label='recall')\n",
    "    \n",
    "    # threshold 값 X 축의 Scale을 0.1 단위로 변경\n",
    "    start, end = plt.xlim()\n",
    "    plt.xticks(np.round(np.arange(start, end, 0.1),2))\n",
    "    \n",
    "    # x축, y축 label과 legend, 그리고 grid 설정\n",
    "    plt.xlabel('Threshold value'); plt.ylabel('Precision and Recall value')\n",
    "    plt.legend(); plt.grid()\n",
    "    plt.show()\n",
    "    \n",
    "precision_recall_curve_plot( y_test, lr_clf.predict_proba(X_test)[:, 1] )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 스코어: 0.7805\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score \n",
    "f1 = f1_score(y_test , pred)\n",
    "print('F1 스코어: {0:.4f}'.format(f1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "임곗값: 0.4\n",
      "오차 행렬\n",
      "[[99 19]\n",
      " [10 51]]\n",
      "정확도: 0.8380, 정밀도: 0.7286, 재현율: 0.8361, F1:0.7786\n",
      "임곗값: 0.45\n",
      "오차 행렬\n",
      "[[103  15]\n",
      " [ 12  49]]\n",
      "정확도: 0.8492, 정밀도: 0.7656, 재현율: 0.8033, F1:0.7840\n",
      "임곗값: 0.5\n",
      "오차 행렬\n",
      "[[104  14]\n",
      " [ 13  48]]\n",
      "정확도: 0.8492, 정밀도: 0.7742, 재현율: 0.7869, F1:0.7805\n",
      "임곗값: 0.55\n",
      "오차 행렬\n",
      "[[109   9]\n",
      " [ 15  46]]\n",
      "정확도: 0.8659, 정밀도: 0.8364, 재현율: 0.7541, F1:0.7931\n",
      "임곗값: 0.6\n",
      "오차 행렬\n",
      "[[112   6]\n",
      " [ 16  45]]\n",
      "정확도: 0.8771, 정밀도: 0.8824, 재현율: 0.7377, F1:0.8036\n"
     ]
    }
   ],
   "source": [
    "def get_clf_eval(y_test , pred):\n",
    "    confusion = confusion_matrix( y_test, pred)\n",
    "    accuracy = accuracy_score(y_test , pred)\n",
    "    precision = precision_score(y_test , pred)\n",
    "    recall = recall_score(y_test , pred)\n",
    "    # F1 스코어 추가\n",
    "    f1 = f1_score(y_test,pred)\n",
    "    print('오차 행렬')\n",
    "    print(confusion)\n",
    "    # f1 score print 추가\n",
    "    print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f}, F1:{3:.4f}'.format(accuracy, precision, recall, f1))\n",
    "\n",
    "thresholds = [0.4 , 0.45 , 0.50 , 0.55 , 0.60]\n",
    "pred_proba = lr_clf.predict_proba(X_test)\n",
    "get_eval_by_threshold(y_test, pred_proba[:,1].reshape(-1,1), thresholds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-5 ROC Curve와 AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "샘플 추출을 위한 임곗값 배열의 index: [ 1  6 11 16 21 26 31 36 41 46 51]\n",
      "샘플 index로 추출한 임곗값:  [0.97 0.65 0.63 0.56 0.45 0.38 0.31 0.13 0.12 0.11 0.1 ]\n",
      "샘플 임곗값별 FPR:  [0.    0.017 0.034 0.076 0.127 0.186 0.237 0.576 0.619 0.754 0.814]\n",
      "샘플 임곗값별 TPR:  [0.033 0.639 0.705 0.754 0.803 0.852 0.902 0.902 0.951 0.967 1.   ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# 레이블 값이 1일때의 예측 확률을 추출 \n",
    "pred_proba_class1 = lr_clf.predict_proba(X_test)[:, 1] \n",
    "\n",
    "fprs , tprs , thresholds = roc_curve(y_test, pred_proba_class1)\n",
    "# 반환된 임곗값 배열에서 샘플로 데이터를 추출하되, 임곗값을 5 Step으로 추출. \n",
    "# thresholds[0]은 max(예측확률)+1로 임의 설정됨. 이를 제외하기 위해 np.arange는 1부터 시작\n",
    "thr_index = np.arange(1, thresholds.shape[0], 5)\n",
    "print('샘플 추출을 위한 임곗값 배열의 index:', thr_index)\n",
    "print('샘플 index로 추출한 임곗값: ', np.round(thresholds[thr_index], 2))\n",
    "\n",
    "# 5 step 단위로 추출된 임계값에 따른 FPR, TPR 값\n",
    "print('샘플 임곗값별 FPR: ', np.round(fprs[thr_index], 3))\n",
    "print('샘플 임곗값별 TPR: ', np.round(tprs[thr_index], 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# 레이블 값이 1일때의 예측 확률을 추출 \n",
    "pred_proba_class1 = lr_clf.predict_proba(X_test)[:, 1] \n",
    "print('max predict_proba:', np.max(pred_proba_class1))\n",
    "\n",
    "fprs , tprs , thresholds = roc_curve(y_test, pred_proba_class1)\n",
    "print('thresholds[0]:', thresholds[0])\n",
    "# 반환된 임곗값 배열 로우가 47건이므로 샘플로 10건만 추출하되, 임곗값을 5 Step으로 추출. \n",
    "thr_index = np.arange(0, thresholds.shape[0], 5)\n",
    "print('샘플 추출을 위한 임곗값 배열의 index 10개:', thr_index)\n",
    "print('샘플용 10개의 임곗값: ', np.round(thresholds[thr_index], 2))\n",
    "\n",
    "# 5 step 단위로 추출된 임계값에 따른 FPR, TPR 값\n",
    "print('샘플 임곗값별 FPR: ', np.round(fprs[thr_index], 3))\n",
    "print('샘플 임곗값별 TPR: ', np.round(tprs[thr_index], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc_curve_plot(y_test , pred_proba_c1):\n",
    "    # 임곗값에 따른 FPR, TPR 값을 반환 받음. \n",
    "    fprs , tprs , thresholds = roc_curve(y_test ,pred_proba_c1)\n",
    "\n",
    "    # ROC Curve를 plot 곡선으로 그림. \n",
    "    plt.plot(fprs , tprs, label='ROC')\n",
    "    # 가운데 대각선 직선을 그림. \n",
    "    plt.plot([0, 1], [0, 1], 'k--', label='Random')\n",
    "    \n",
    "    # FPR X 축의 Scale을 0.1 단위로 변경, X,Y 축명 설정등   \n",
    "    start, end = plt.xlim()\n",
    "    plt.xticks(np.round(np.arange(start, end, 0.1),2))\n",
    "    plt.xlim(0,1); plt.ylim(0,1)\n",
    "    plt.xlabel('FPR( 1 - Sensitivity )'); plt.ylabel('TPR( Recall )')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "roc_curve_plot(y_test, lr_clf.predict_proba(X_test)[:, 1] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "### 아래는 roc_auc_score()의 인자를 잘못 입력한 것으로, 책에서 수정이 필요한 부분입니다. \n",
    "### 책에서는 roc_auc_score(y_test, pred)로 예측 타겟값을 입력하였으나 \n",
    "### roc_auc_score(y_test, y_score)로 y_score는 predict_proba()로 호출된 예측 확률 ndarray중 Positive 열에 해당하는 ndarray입니다. \n",
    "\n",
    "#pred = lr_clf.predict(X_test)\n",
    "#roc_score = roc_auc_score(y_test, pred)\n",
    "\n",
    "pred_proba = lr_clf.predict_proba(X_test)[:, 1]\n",
    "roc_score = roc_auc_score(y_test, pred_proba)\n",
    "print('ROC AUC 값: {0:.4f}'.format(roc_score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clf_eval(y_test, pred=None, pred_proba=None):\n",
    "    confusion = confusion_matrix( y_test, pred)\n",
    "    accuracy = accuracy_score(y_test , pred)\n",
    "    precision = precision_score(y_test , pred)\n",
    "    recall = recall_score(y_test , pred)\n",
    "    f1 = f1_score(y_test,pred)\n",
    "    # ROC-AUC 추가 \n",
    "    roc_auc = roc_auc_score(y_test, pred_proba)\n",
    "    print('오차 행렬')\n",
    "    print(confusion)\n",
    "    # ROC-AUC print 추가\n",
    "    print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f},\\\n",
    "          F1: {3:.4f}, AUC:{4:.4f}'.format(accuracy, precision, recall, f1, roc_auc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
